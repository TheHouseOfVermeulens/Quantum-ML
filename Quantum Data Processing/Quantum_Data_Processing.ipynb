{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Quantum_Data_Processing.ipynb","provenance":[],"authorship_tag":"ABX9TyPM4nw6FXvZimW4kG4d4cG0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Quantum Data Processing**\n","\n","This notebook covers the topic of quantum data processing. We will see how quantum data processing algorithms are implemented in day-to-day life. Code examples are presented for algorithms such as k-means, k-medians, and quantum clustering."],"metadata":{"id":"95r4HnAt7WHc"}},{"cell_type":"markdown","source":["\n","**Quantum k-means**\n","\n","The quantum k-means technique is applied using a quantum circuit that can have training vectors. The training vectors are the initial centroids, and the centroids are computed after every step. The circuit can be changed by using a rotated training vector. The number of training vectors is increased based on the number of clusters. The pseudo-algorithm steps are shown here: \n","\n","1. Input the k cluster groups, and input the data points. \n","\n","2. Initialize the k centroids randomly. \n","3. Iterate all the input data points to identify the cluster group to them. \n","\n","4. Compute the quantum interference circuit. \n","\n","5. Filter the interference probabilities. \n","\n","6. Add the high probability centroids into the dictionary. \n","\n","7. The previous three methods are computed for the set of data points.\n","\n","For k clusters, the N number of quantum machines can be modeled for the quantum k-means technique. The quantum state consists of the group of centroids that are the result of the algorithm. Parallelization can be done by breaking down the input data into different sets for each quantum machine to execute the algorithm. The quantum state is aggregated and used for iterations. The Iris data set that was discussed in the previous chapter can be clustered in three groups (setosa, versicolor, virginica) based on the petal’s and sepal’s width and height. The technique tries to identify the cluster groups with lesser variation within the cluster. The other application is to classify people based on their income and spending into k clusters. [1]"],"metadata":{"id":"up7vi98D9Kqz"}},{"cell_type":"code","source":["import matplotlib.pyplot as plot\n","import pandas as pand!pip install qiskit\n","from qiskit import QuantumRegister, ClassicalRegister\n","from qiskit import QuantumCircuit\n","from qiskit import Aer, execute\n","from numpy import pi\n","\n","figure, axis = plot.subplots()\n","axis.set(xlabel='Feature 1', ylabel='Feature 2')\n","\n","\n","data_input = pand.read_csv('kmeans_input.csv',\n","    usecols=['Feature 1', 'Feature 2', 'Class'])\n","\n","\n","isRed = data_input['Class'] == 'Red'\n","isGreen = data_input['Class'] == 'Green'\n","isBlack = data_input['Class'] == 'Black'\n","\n","# Filter data\n","redData = data_input[isRed].drop(['Class'], axis=1)\n","greenData = data_input[isGreen].drop(['Class'], axis=1)\n","blackData = data_input[isBlack].drop(['Class'], axis=1)\n","\n","\n","y_p = 0.141\n","x_p = -0.161\n","\n","xgc = sum(redData['Feature 1']) / len(redData['Feature 1'])\n","xbc = sum(greenData['Feature 1']) / len(greenData['Feature 1'])\n","xkc = sum(blackData['Feature 1']) / len(blackData['Feature 1'])\n","\n","# Finding the y-coords of the centroids\n","ygc = sum(redData['Feature 2']) / len(redData['Feature 2'])\n","ybc = sum(greenData['Feature 2']) / len(greenData['Feature 2'])\n","ykc = sum(blackData['Feature 2']) / len(blackData['Feature 2'])\n","\n","# Plotting the centroids\n","plot.plot(xgc, ygc, 'rx')\n","plot.plot(xbc, ybc, 'gx')\n","plot.plot(xkc, ykc, 'kx')\n","\n","\n","plot.plot(x_p, y_p, 'bo')\n","\n","# Setting the axis ranges\n","plot.axis([-1, 1, -1, 1])\n","\n","plot.show()\n","\n","# Calculating theta and phi values\n","phi_list = [((x + 1) * pi / 2) for x in [x_p, xgc, xbc, xkc]]\n","theta_list = [((x + 1) * pi / 2) for x in [y_p, ygc, ybc, ykc]]\n","\n","quantumregister = QuantumRegister(3, 'quantumregister')\n","\n","\n","classicregister = ClassicalRegister(1, 'classicregister')\n","\n","quantum_circuit = QuantumCircuit(quantumregister, classicregister, name='qc')\n","\n","\n","backend = Aer.get_backend('qasm_simulator')\n","\n","\n","quantum_results_list = []\n","\n","\n","for i in range(1, 4):\n","    quantum_circuit.h(quantumregister[2])\n","\n","   \n","    quantum_circuit.u3(theta_list[0], phi_list[0], 0, quantumregister[0])           \n","    quantum_circuit.u3(theta_list[i], phi_list[i], 0, quantumregister[1]) \n","\n","    quantum_circuit.cswap(quantumregister[2], quantumregister[0], quantumregister[1])\n","    quantum_circuit.h(quantumregister[2])\n","\n","    quantum_circuit.measure(quantumregister[2], classicregister[0])\n","\n","    quantum_circuit.reset(quantumregister)\n","\n","    job = execute(quantum_circuit, backend=backend, shots=1024)\n","    result = job.result().get_counts(quantum_circuit)\n","    quantum_results_list.append(result['1'])\n","\n","print(quantum_results_list)\n","\n","\n","\n","class_list = ['Red', 'Green', 'Black']\n","\n","\n","quantum_p_class = class_list[quantum_results_list.index(min(quantum_results_list))]\n","\n","\n","distances_list = [((x_p - i[0])**2 + (y_p - i[1])**2)**0.5 for i in [(xgc, ygc), (xbc, ybc), (xkc, ykc)]]\n","classical_p_class = class_list[distances_list.index(min(distances_list))]\n","\n","print(\"\"\"using quantumdistance algorithm,\n"," the new data point is related to the\"\"\", quantum_p_class, \n"," 'class.\\n')\n","print('Euclidean distances are listed: ', distances_list, '\\n')\n","print(\"\"\"based on euclidean distance calculations,\n"," the new data point is related to the\"\"\", classical_p_class, \n"," 'class.')"],"metadata":{"id":"3Qagalg7-Pv8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The input points are read from the Excel file that has the colors red, green, and black. A new point is added to use the quantum k-means algorithm to find which class color it belongs to. Using the quantum distance algorithm, the new data point [72, 60, 125] is related to the Green class. The distances measured are based on Euclidean distances. \n","\n","[0.520285324797846, 0.4905204028376393, 0.7014755294377704]"],"metadata":{"id":"YN1dcsD9AEGs"}},{"cell_type":"markdown","source":["**Quantum K-Medians**\n","\n","The quantum k-medians technique is the computation of the cluster centroids in a cluster group by using the median of the data points. A median is computed based on the minimal distance from all the data points. The technique is related to minimizing the sum of the distance between a point and the median of the data set. The minimization of the distance is computed based on a quantum minimization algorithm using Grover’s search. The Euclidean distance between the points is used as the distance algorithm.\n","\n","The steps for the pseudo-algorithm are shown here: \n","\n","1. The input is the k cluster groups and input data points. \n","\n","2. Initialize the k centroids randomly based on the median of the data points. \n","\n","3. All the input data points are iterated to identify the cluster group to them.\n","\n","4. The quantum interference circuit is computed. \n","\n","5. The interference probabilities are filtered. \n","\n","6. The high probability centroids are added into the dictionary. \n","\n","7. The previous three methods are computed for the set of data points."],"metadata":{"id":"68D7X6ugAgrH"}},{"cell_type":"code","source":["import matplotlib.pyplot as plot\n","import pandas as pand\n","from qiskit import QuantumRegister, ClassicalRegister\n","from qiskit import QuantumCircuit\n","from qiskit import Aer, execute\n","from numpy import pi\n","\n","figure, axis = plot.subplots()\n","axis.set(xlabel='Feature 1', ylabel='Feature 2')\n","\n","\n","data_input = pand.read_csv('kmeans_input.csv',\n","    usecols=['Feature 1', 'Feature 2', 'Class'])\n","\n","\n","isRed = data_input['Class'] == 'Red'\n","isGreen = data_input['Class'] == 'Green'\n","isBlack = data_input['Class'] == 'Black'\n","\n","# Filter data\n","redData = data_input[isRed].drop(['Class'], axis=1)\n","greenData = data_input[isGreen].drop(['Class'], axis=1)\n","blackData = data_input[isBlack].drop(['Class'], axis=1)\n","\n","\n","y_p = 0.141\n","x_p = -0.161\n","\n","xgc = sum(redData['Feature 1']) / len(redData['Feature 1'])\n","xbc = sum(greenData['Feature 1']) / len(greenData['Feature 1'])\n","xkc = sum(blackData['Feature 1']) / len(blackData['Feature 1'])\n","\n","# Finding the y-coords of the centroids\n","ygc = sum(redData['Feature 2']) / len(redData['Feature 2'])\n","ybc = sum(greenData['Feature 2']) / len(greenData['Feature 2'])\n","ykc = sum(blackData['Feature 2']) / len(blackData['Feature 2'])\n","\n","# Plotting the centroids\n","plot.plot(xgc, ygc, 'rx')\n","plot.plot(xbc, ybc, 'gx')\n","plot.plot(xkc, ykc, 'kx')\n","\n","\n","plot.plot(x_p, y_p, 'bo')\n","\n","# Setting the axis ranges\n","plot.axis([-1, 1, -1, 1])\n","\n","plot.show()\n","\n","# Calculating theta and phi values\n","phi_list = [((x + 1) * pi / 2) for x in [x_p, xgc, xbc, xkc]]\n","theta_list = [((x + 1) * pi / 2) for x in [y_p, ygc, ybc, ykc]]\n","\n","quantumregister = QuantumRegister(3, 'quantumregister')\n","\n","\n","classicregister = ClassicalRegister(1, 'classicregister')\n","\n","quantum_circuit = QuantumCircuit(quantumregister, classicregister, name='qc')\n","\n","\n","backend = Aer.get_backend('qasm_simulator')\n","\n","\n","quantum_results_list = []\n","\n","\n","for i in range(1, 4):\n","    quantum_circuit.h(quantumregister[2])\n","\n","   \n","    quantum_circuit.u3(theta_list[0], phi_list[0], 0, quantumregister[0])           \n","    quantum_circuit.u3(theta_list[i], phi_list[i], 0, quantumregister[1]) \n","\n","    quantum_circuit.cswap(quantumregister[2], quantumregister[0], quantumregister[1])\n","    quantum_circuit.h(quantumregister[2])\n","\n","    quantum_circuit.measure(quantumregister[2], classicregister[0])\n","\n","    quantum_circuit.reset(quantumregister)\n","\n","    job = execute(quantum_circuit, backend=backend, shots=1024)\n","    result = job.result().get_counts(quantum_circuit)\n","    quantum_results_list.append(result['1'])\n","\n","print(quantum_results_list)\n","\n","\n","\n","class_list = ['Red', 'Green', 'Black']\n","\n","\n","quantum_p_class = class_list[quantum_results_list.index(min(quantum_results_list))]\n","\n","\n","distances_list = [((x_p - i[0])**2 + (y_p - i[1])**2)**0.5 for i in [(xgc, ygc), (xbc, ybc), (xkc, ykc)]]\n","classical_p_class = class_list[distances_list.index(min(distances_list))]\n","\n","print(\"\"\"using quantumdistance algorithm,\n"," the new data point is related to the\"\"\", quantum_p_class, \n"," 'class.\\n')\n","print('Euclidean distances are listed: ', distances_list, '\\n')\n","print(\"\"\"based on euclidean distance calculations,\n"," the new data point is related to the\"\"\", classical_p_class, \n"," 'class.')"],"metadata":{"id":"OD-IvJc9B37Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Quantum Clustering** \n","\n","The quantum clustering algorithm (see Figure 10-9) is based on the gradient descent technique. It is used to find the quantum potential at a constant learning rate and computing the cluster center. Using quantum mechanics–based principles, quantum clustering techniques find groups with complex shapes. The technique identifies the group of any shape by computing the group center. Quantum clustering is based on the inversion problem in quantum mechanics. The quantum clustering technique helps to get a particle distribution that is estimated based on the potential function. The algorithm finds the group center. For each group in the center, it assigns the center. The wave function is identified from the Schrodinger equation solution. Let’s look at the steps for the quantum clustering algorithm: \n","\n","1. The weights for each data feature are identified, and the parameters are selected based on the input data. \n","\n","2. The number of groups/measurement scale is set to zero.\n","\n","3. The weighted measures are calculated based on the quantum clustering distance method. \n","\n","4. The parameter and the potential energy based on the data are estimated.\n","\n","5. The group number is increased by 1. \n","\n","6. The minimum potential energy is identified at the group’s center. \n","\n","7. All the data points are grouped by the distance metric, and it needs to be less than the measurement scale. The algorithm ends when the number of data points is zero for the distance metric criterion. Otherwise, the algorithm goes back to step 5. \n","\n","The quantum clustering algorithm has a single parameter. The algorithm is partition based and is an unsupervised learning technique. The processing time is higher because of the preprocessing required for grouping. The measurement scale is static, and the method is not dependent on the features. In this method, the precision of the grouping is dependent on the amount of learning. [1]"],"metadata":{"id":"hspvpmC9EHfB"}},{"cell_type":"code","source":["import numpy as nump\n","from scipy.spatial import distance as spatDistance\n","from sklearn.decomposition import PCA as decomPCA\n","import matplotlib.pyplot as plot\n","from mpl_toolkits.mplot3d import Axes3D as mplAxes3D\n","\n","def getVGradient(data:nump.ndarray,sigma,x:nump.ndarray=None,coeffs:nump.ndarray=None):\n","   \n","    \n","    if x is None:\n","        x = data.copy()\n","    \n","    if coeffs is None:\n","        coeffs = nump.ones((data.shape[0],))\n","    \n","        \n","    twoSigmaSquared = 2*sigma**2\n","        \n","    data = data[nump.newaxis,:,:]\n","    x = x[:,nump.newaxis,:]\n","    differences = x-data\n","    squaredDifferences = nump.sum(nump.square(differences),axis=2)\n","    gaussian = nump.exp(-(1/twoSigmaSquared)*squaredDifferences)\n","    laplacian = nump.sum(coeffs*gaussian*squaredDifferences,axis=1)\n","    parzen = nump.sum(coeffs*gaussian,axis=1)\n","    v = 1 + (1/twoSigmaSquared)*laplacian/parzen\n","\n","    dv = -1*(1/parzen[:,nump.newaxis])*nump.sum(differences*((coeffs*gaussian)[:,:,nump.newaxis])*(twoSigmaSquared*(v[:,nump.newaxis,nump.newaxis])-(squaredDifferences[:,:,nump.newaxis])),axis=1)\n","    \n","    v = v-1\n","    \n","    return v, dv\n","\n","def getSGradient(data:nump.ndarray,sigma,x:nump.ndarray=None,coeffs:nump.ndarray=None):\n","   \n","    if x is None:\n","        x = data.copy()\n","        \n","    if coeffs is None:\n","        coeffs = nump.ones((data.shape[0],))\n","    \n","    twoSigmaSquared = 2 * sigma ** 2\n","    \n","    data = data[nump.newaxis, :, :]\n","    x = x[:, nump.newaxis, :]\n","    differences = x - data\n","    squaredDifferences = nump.sum(nump.square(differences), axis=2)\n","    gaussian = nump.exp(-(1 / twoSigmaSquared) * squaredDifferences)\n","    laplacian = nump.sum(coeffs*gaussian * squaredDifferences, axis=1)\n","    parzen = nump.sum(coeffs*gaussian, axis=1)\n","    v = (1 / twoSigmaSquared) * laplacian / parzen\n","    s = v + nump.log(nump.abs(parzen))\n","    \n","    ds = (1 / parzen[:, nump.newaxis]) * nump.sum(differences * ((coeffs*gaussian)[:, :, nump.newaxis]) * (\n","    twoSigmaSquared * (v[:, nump.newaxis, nump.newaxis]) - (squaredDifferences[:, :, nump.newaxis])), axis=1)\n","    \n","    return s, ds\n","\n","def getPGradient(data:nump.ndarray,sigma,x:nump.ndarray=None,coeffs:nump.ndarray=None):\n","\n","    if x is None:\n","        x = data.copy()\n","        \n","    if coeffs is None:\n","        coeffs = nump.ones((data.shape[0],))\n","    \n","    twoSigmaSquared = 2 * sigma ** 2\n","    \n","    data = data[nump.newaxis, :, :]\n","    x = x[:, nump.newaxis, :]\n","    differences = x - data\n","    squaredDifferences = nump.sum(nump.square(differences), axis=2)\n","    gaussian = nump.exp(-(1 / twoSigmaSquared) * squaredDifferences)\n","    p = nump.sum(coeffs*gaussian,axis=1)\n","    \n","    dp = -1*nump.sum(differences * ((coeffs*gaussian)[:, :, nump.newaxis]) * twoSigmaSquared,axis=1)\n","    \n","    return p, dp\n","\n","def getApproximateParzenValues(data:nump.ndarray,sigma,voxelSize):\n","\n","    newData = getUniqueRows(nump.floor(data/voxelSize)*voxelSize+voxelSize/2)[0]\n","    \n","    nMat = nump.exp(-1*spatDistance.squareform(nump.square(spatDistance.pdist(newData)))/(4*sigma**2))\n","    mMat = nump.exp(-1 * nump.square(spatDistance.cdist(newData,data)) / (4 * sigma ** 2))\n","    cMat = nump.linalg.solve(nMat,mMat)\n","    coeffs = nump.sum(cMat,axis=1)\n","    coeffs = data.shape[0]*coeffs/sum(coeffs)\n","    \n","    return newData,coeffs\n","\n","def getUniqueRows(x):\n","    y = nump.ascontiguousarray(x).view(nump.dtype((nump.void, x.dtype.itemsize * x.shape[1])))\n","    _, inds,indsInverse,counts = nump.unique(y, return_index=True,return_inverse=True,return_counts=True)\n","\n","    xUnique = x[inds]\n","    return xUnique,inds,indsInverse,counts\n","\n","def getGradientDescent(data,sigma,repetitions=1,stepSize=None,clusteringType='v',recalculate=False,returnHistory=False,stopCondition=True,voxelSize=None):\n","    \n","    n = data.shape[0]\n","\n","    useApproximation = (voxelSize is not None)\n","    \n","    if stepSize is None:\n","        stepSize = sigma/10\n","    \n","    if clusteringType == 'v':\n","        gradientFunction = getVGradient\n","    elif clusteringType == 's':\n","        gradientFunction = getSGradient\n","    else:\n","        gradientFunction = getPGradient\n","\n","    if useApproximation:\n","        newData, coeffs = getApproximateParzenValues(data, sigma, voxelSize)\n","    else:\n","        coeffs = None\n","\n","    if recalculate:\n","        if useApproximation:\n","            x = nump.vstack((data,newData))\n","            data = x[data.shape[0]:]\n","        else:\n","            x = data\n","    else:\n","        if useApproximation:\n","            x = data\n","            data = newData\n","        else:\n","            x = data.copy()\n","        \n","        \n","    if returnHistory:\n","        xHistory = nump.zeros((n,x.shape[1],repetitions+1))\n","        xHistory[:,:,0] = x[:n,:].copy()\n","        \n","    if stopCondition:\n","        prevX = x[:n].copy()\n","\n","    for i in range(repetitions):\n","        if ((i>0) and (i%10==0)):\n","            if stopCondition:\n","                if nump.all(nump.linalg.norm(x[:n]-prevX,axis=1) < nump.sqrt(3*stepSize**2)):\n","                    i = i-1\n","                    break\n","                prevX = x[:n].copy()\n","            \n","        f,df = gradientFunction(data,sigma,x,coeffs)\n","        df = df/nump.linalg.norm(df,axis=1)[:,nump.newaxis]\n","        x[:] = x + stepSize*df\n","\n","        if returnHistory:\n","            xHistory[:, :, i+1] = x[:n].copy()\n","            \n","    x = x[:n]\n","\n","    if returnHistory:\n","        xHistory = xHistory[:,:,:(i+2)]\n","        return x,xHistory\n","    else:\n","        return x\n","\n","def PerformFinalClusteringAlgo(data,stepSize):\n","    clusters = nump.zeros((data.shape[0]))\n","    i = nump.array([0])\n","    c = 0\n","    spatDistances = spatDistance.squareform(spatDistance.pdist(data))\n","    while i.shape[0]>0:\n","        i = i[0]\n","        inds = nump.argwhere(clusters==0)\n","        clusters[inds[spatDistances[i,inds] <= 3*stepSize]] = c\n","        c += 1\n","        i = nump.argwhere(clusters==0)\n","    return clusters\n","\n","def displayClusteringValues(xHistory,clusters=None):\n","\n","    plot.ion()\n","    plot.figure(figsize=(20, 12))\n","    if clusters is None:\n","        clusters = nump.zeros((xHistory.shape[0],))\n","    if xHistory.shape[1] == 1:\n","\n","        sc = plot.scatter(xHistory[:,:,0],xHistory[:,:,0]*0,c=clusters,s=10)\n","        plot.xlim((nump.min(xHistory),nump.max(xHistory)))\n","        plot.ylim((-1,1))\n","        for i in range(xHistory.shape[2]):\n","            sc.set_offsets(xHistory[:, :, i])\n","            plot.title('step #' + str(i) + '/' + str(xHistory.shape[2]-1))\n","            plot.pause(0.05)\n","    elif xHistory.shape[1] == 2:\n","\n","        sc = plot.scatter(xHistory[:, 0, 0], xHistory[:, 1, 0] , c=clusters, s=20)\n","        plot.xlim((nump.min(xHistory[:,0,:]), nump.max(xHistory[:,0,:])))\n","        plot.ylim((nump.min(xHistory[:, 1, :]), nump.max(xHistory[:, 1, :])))\n","        for i in range(xHistory.shape[2]):\n","            sc.set_offsets(xHistory[:, :, i])\n","            plot.title('step #' + str(i) + '/' + str(xHistory.shape[2]-1))\n","            plot.pause(0.2)\n","    else:\n","        if xHistory.shape[1] > 3:\n","            pca = decomPCA(3)\n","            pca.fit(xHistory[:,:,0])\n","            newXHistory = nump.zeros((xHistory.shape[0],3,xHistory.shape[2]))\n","            for i in range(xHistory.shape[2]):\n","                newXHistory[:,:,i] = pca.transform(xHistory[:,:,i])\n","            xHistory = newXHistory\n","\n","\n","        ax = plot.axes(projection='3d')\n","        sc = ax.scatter(xHistory[:, 0, 0], xHistory[:, 1, 0],xHistory[:, 2, 0], c=clusters, s=20)\n","        ax.set_xlim((nump.min(xHistory[:, 0, :]), nump.max(xHistory[:, 0, :])))\n","        ax.set_ylim((nump.min(xHistory[:, 1, :]), nump.max(xHistory[:, 1, :])))\n","        ax.set_zlim((nump.min(xHistory[:, 2, :]), nump.max(xHistory[:, 2, :])))\n","        for i in range(xHistory.shape[2]):\n","            sc._offsets3d =  (nump.ravel(xHistory[:, 0, i]),nump.ravel(xHistory[:, 1, i]),nump.ravel(xHistory[:, 2, i]))\n","            plot.gcf().suptitle('step #' + str(i) + '/' + str(xHistory.shape[2]-1))\n","            plot.pause(0.01)\n","            \n","    plot.show()"],"metadata":{"id":"Oa_7QWCLFx9A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as nump\n","import quantum_cluster\n","\n","\n","\n","types = ['f8', 'f8', 'f8','f8','U50']\n","\n","data_res = nump.loadtxt('iris_input.csv', delimiter=',')\n","\n","print(data_res)\n","data_res = data_res[:,:4]\n","\n","sigma_val=0.55\n","repetitionsVal=100\n","stepSizeVal=0.1\n","clusteringTypeVal='v'\n","isRecalculate=False\n","isReturnHistory=True\n","isStopCondition=True\n","voxelSizeVal = None\n","\n","xval,xHistoryVal = quantum_cluster.getGradientDescent(data_res,sigma=sigma_val,repetitions=repetitionsVal,stepSize=stepSizeVal,clusteringType=clusteringTypeVal,recalculate=isRecalculate,returnHistory=isReturnHistory,stopCondition=isStopCondition,voxelSize=voxelSizeVal)\n","\n","clusters_res = quantum_cluster.PerformFinalClusteringAlgo(xval,stepSizeVal)\n","\n","quantum_cluster.displayClusteringValues(xHistoryVal,clusters_res)"],"metadata":{"id":"pfHFmeCyFwvP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Quantum Manifold Embedding** \n","\n","Quantum manifold embedding has sections that are Euclidean spaces. Euclidean spaces represent the quantum state in a quantum system. The Euclidean space has m vectors related to m dimensions. [1]"],"metadata":{"id":"uIVGIcVyGfKt"}},{"cell_type":"markdown","source":["\n","References\n","[1] Bhagvan Kommadi"],"metadata":{"id":"4YzoZ3jqF6n5"}}]}
